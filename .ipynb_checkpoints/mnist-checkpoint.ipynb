{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "train_set = mnist.train.images*2 - 1\n",
    "train_labels = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, Y, reuse=None):\n",
    "\twith tf.variable_scope('gen',reuse=reuse):\n",
    "        \n",
    "\t\tip = tf.concat([z, Y], 1)\n",
    "\t\thidden1 = tf.layers.dense(inputs=ip,units=128)\n",
    "\n",
    "\t\talpha = 0.01\n",
    "\t\thidden1 = tf.maximum(alpha*hidden1, hidden1)\n",
    "\n",
    "\t\thidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "\n",
    "\t\thidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "\n",
    "\t\toutput = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh)\n",
    "\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X, Y, reuse=None):\n",
    "\twith tf.variable_scope('dis',reuse=reuse):\n",
    "        \n",
    "\t\tip = tf.concat([X, Y], 1)\n",
    "\t\thidden1 = tf.layers.dense(inputs=ip,units=128)\n",
    "\n",
    "\t\talpha = 0.01\n",
    "\t\thidden1 = tf.maximum(alpha*hidden1, hidden1)\n",
    "\n",
    "\t\thidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "\n",
    "\t\thidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "\n",
    "\t\tlogits = tf.layers.dense(hidden2, units=1)\n",
    "\t\toutput = tf.sigmoid(logits)\n",
    "\n",
    "\t\treturn output,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "z = tf.placeholder(tf.float32,shape=[None,100])\n",
    "onehot = np.eye(10)\n",
    "\n",
    "G = generator(z, y)\n",
    "\n",
    "D_output_real , D_logits_real = discriminator(real_images, y)\n",
    "\n",
    "D_output_fake , D_logits_fake = discriminator(G, y, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSSES\n",
    "def loss_func(logits_in, labels_in):\n",
    "\treturn tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "\t\tlogits=logits_in,labels=labels_in))\n",
    "\n",
    "D_real_loss = loss_func(D_logits_real, tf.ones_like(D_logits_real)*0.9) #SMOOTHING\n",
    "D_fake_loss = loss_func(D_logits_fake, tf.zeros_like(D_logits_fake))\n",
    "\n",
    "D_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "G_loss = loss_func(D_logits_fake, tf.ones_like(D_logits_fake))\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss,var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss,var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 100\n",
    "init = tf.global_variables_initializer()\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON EPOCH 0: D_loss=0.5457248687744141, G_loss=3.53469181060791\n",
      "ON EPOCH 1: D_loss=1.1166365146636963, G_loss=3.127018928527832\n",
      "ON EPOCH 2: D_loss=3.5645742416381836, G_loss=0.49182724952697754\n",
      "ON EPOCH 3: D_loss=0.9169942140579224, G_loss=4.700067043304443\n",
      "ON EPOCH 4: D_loss=1.1579642295837402, G_loss=1.3352512121200562\n",
      "ON EPOCH 5: D_loss=0.9328508377075195, G_loss=1.9422121047973633\n",
      "ON EPOCH 6: D_loss=1.5616686344146729, G_loss=1.6153124570846558\n",
      "ON EPOCH 7: D_loss=1.0056209564208984, G_loss=4.470495223999023\n",
      "ON EPOCH 8: D_loss=1.0202518701553345, G_loss=3.702606439590454\n",
      "ON EPOCH 9: D_loss=0.9343563914299011, G_loss=4.162499904632568\n",
      "ON EPOCH 10: D_loss=0.6313896179199219, G_loss=3.348505973815918\n",
      "ON EPOCH 11: D_loss=0.9821710586547852, G_loss=2.0511908531188965\n",
      "ON EPOCH 12: D_loss=0.9229683876037598, G_loss=1.7619415521621704\n",
      "ON EPOCH 13: D_loss=0.7422417998313904, G_loss=3.2380504608154297\n",
      "ON EPOCH 14: D_loss=1.5036574602127075, G_loss=2.0144619941711426\n",
      "ON EPOCH 15: D_loss=0.8161377906799316, G_loss=3.0861809253692627\n",
      "ON EPOCH 16: D_loss=0.956372857093811, G_loss=3.161702871322632\n",
      "ON EPOCH 17: D_loss=1.1315083503723145, G_loss=2.1926474571228027\n",
      "ON EPOCH 18: D_loss=0.7907449007034302, G_loss=3.959811210632324\n",
      "ON EPOCH 19: D_loss=1.2625541687011719, G_loss=1.2709535360336304\n",
      "ON EPOCH 20: D_loss=0.9058217406272888, G_loss=1.9958709478378296\n",
      "ON EPOCH 21: D_loss=0.7132492065429688, G_loss=3.2497448921203613\n",
      "ON EPOCH 22: D_loss=0.5244101285934448, G_loss=2.6160428524017334\n",
      "ON EPOCH 23: D_loss=0.9607663750648499, G_loss=3.0398082733154297\n",
      "ON EPOCH 24: D_loss=0.7583768963813782, G_loss=2.4427168369293213\n",
      "ON EPOCH 25: D_loss=0.7391673922538757, G_loss=2.37477970123291\n",
      "ON EPOCH 26: D_loss=0.674015998840332, G_loss=3.0104129314422607\n",
      "ON EPOCH 27: D_loss=0.6616662740707397, G_loss=3.241807460784912\n",
      "ON EPOCH 28: D_loss=0.7531148195266724, G_loss=2.5649938583374023\n",
      "ON EPOCH 29: D_loss=0.733999490737915, G_loss=3.9550533294677734\n",
      "ON EPOCH 30: D_loss=0.6178945899009705, G_loss=2.302868366241455\n",
      "ON EPOCH 31: D_loss=0.7060942649841309, G_loss=2.7318637371063232\n",
      "ON EPOCH 32: D_loss=0.7089622616767883, G_loss=2.7021865844726562\n",
      "ON EPOCH 33: D_loss=0.683672308921814, G_loss=2.805147409439087\n",
      "ON EPOCH 34: D_loss=0.8573546409606934, G_loss=2.447091579437256\n",
      "ON EPOCH 35: D_loss=0.7137577533721924, G_loss=2.4440255165100098\n",
      "ON EPOCH 36: D_loss=0.9108449220657349, G_loss=2.1107804775238037\n",
      "ON EPOCH 37: D_loss=0.9186512231826782, G_loss=2.086228370666504\n",
      "ON EPOCH 38: D_loss=0.7122646570205688, G_loss=2.1238837242126465\n",
      "ON EPOCH 39: D_loss=0.8617351651191711, G_loss=2.09653639793396\n",
      "ON EPOCH 40: D_loss=0.8054629564285278, G_loss=2.1842188835144043\n",
      "ON EPOCH 41: D_loss=0.8190823197364807, G_loss=2.2335054874420166\n",
      "ON EPOCH 42: D_loss=0.723720908164978, G_loss=1.8994319438934326\n",
      "ON EPOCH 43: D_loss=0.8508382439613342, G_loss=2.009059190750122\n",
      "ON EPOCH 44: D_loss=0.830024003982544, G_loss=1.8177417516708374\n",
      "ON EPOCH 45: D_loss=0.8943139314651489, G_loss=1.8939850330352783\n",
      "ON EPOCH 46: D_loss=0.7037754058837891, G_loss=2.002476453781128\n",
      "ON EPOCH 47: D_loss=0.7920565605163574, G_loss=2.014273166656494\n",
      "ON EPOCH 48: D_loss=0.9643268585205078, G_loss=2.0782291889190674\n",
      "ON EPOCH 49: D_loss=0.8396300077438354, G_loss=2.1352643966674805\n",
      "ON EPOCH 50: D_loss=0.8597958087921143, G_loss=1.6122922897338867\n",
      "ON EPOCH 51: D_loss=1.0021116733551025, G_loss=1.9092910289764404\n",
      "ON EPOCH 52: D_loss=0.8148537278175354, G_loss=1.871375560760498\n",
      "ON EPOCH 53: D_loss=0.909272313117981, G_loss=2.05098295211792\n",
      "ON EPOCH 54: D_loss=0.7654604315757751, G_loss=2.4747252464294434\n",
      "ON EPOCH 55: D_loss=0.7641955614089966, G_loss=1.7164504528045654\n",
      "ON EPOCH 56: D_loss=0.8763658404350281, G_loss=2.278017044067383\n",
      "ON EPOCH 57: D_loss=0.6771690249443054, G_loss=2.551013946533203\n",
      "ON EPOCH 58: D_loss=0.7639727592468262, G_loss=2.0887649059295654\n",
      "ON EPOCH 59: D_loss=0.7449631690979004, G_loss=2.600358486175537\n",
      "ON EPOCH 60: D_loss=0.8694475889205933, G_loss=2.358640193939209\n",
      "ON EPOCH 61: D_loss=0.7988145351409912, G_loss=2.0293002128601074\n",
      "ON EPOCH 62: D_loss=0.8694714307785034, G_loss=1.9116401672363281\n",
      "ON EPOCH 63: D_loss=0.9093260765075684, G_loss=1.7069989442825317\n",
      "ON EPOCH 64: D_loss=0.8171340227127075, G_loss=2.2149412631988525\n",
      "ON EPOCH 65: D_loss=0.8688967227935791, G_loss=1.6496638059616089\n",
      "ON EPOCH 66: D_loss=0.8914575576782227, G_loss=1.592368483543396\n",
      "ON EPOCH 67: D_loss=0.7832343578338623, G_loss=1.9131579399108887\n",
      "ON EPOCH 68: D_loss=0.8442091345787048, G_loss=1.7046844959259033\n",
      "ON EPOCH 69: D_loss=0.9386013150215149, G_loss=2.1301355361938477\n",
      "ON EPOCH 70: D_loss=0.9528536200523376, G_loss=1.5001325607299805\n",
      "ON EPOCH 71: D_loss=1.0074653625488281, G_loss=1.3381162881851196\n",
      "ON EPOCH 72: D_loss=0.9560415744781494, G_loss=1.7861888408660889\n",
      "ON EPOCH 73: D_loss=0.7500394582748413, G_loss=1.4981521368026733\n",
      "ON EPOCH 74: D_loss=0.7700549364089966, G_loss=2.134002685546875\n",
      "ON EPOCH 75: D_loss=0.7492571473121643, G_loss=1.7514437437057495\n",
      "ON EPOCH 76: D_loss=0.844032347202301, G_loss=1.9072505235671997\n",
      "ON EPOCH 77: D_loss=0.7906010746955872, G_loss=1.7070322036743164\n",
      "ON EPOCH 78: D_loss=0.9010881781578064, G_loss=1.5878574848175049\n",
      "ON EPOCH 79: D_loss=0.9055452346801758, G_loss=1.7307946681976318\n",
      "ON EPOCH 80: D_loss=0.8247530460357666, G_loss=1.8274716138839722\n",
      "ON EPOCH 81: D_loss=0.8460033535957336, G_loss=1.381606936454773\n",
      "ON EPOCH 82: D_loss=0.8800746202468872, G_loss=1.5814263820648193\n",
      "ON EPOCH 83: D_loss=0.8630105257034302, G_loss=1.3934755325317383\n",
      "ON EPOCH 84: D_loss=0.9321857690811157, G_loss=1.6393158435821533\n",
      "ON EPOCH 85: D_loss=0.7921375036239624, G_loss=1.886013388633728\n",
      "ON EPOCH 86: D_loss=0.878020167350769, G_loss=1.7816435098648071\n",
      "ON EPOCH 87: D_loss=0.8363597989082336, G_loss=1.569585919380188\n",
      "ON EPOCH 88: D_loss=0.9833263158798218, G_loss=1.3136308193206787\n",
      "ON EPOCH 89: D_loss=0.8988974094390869, G_loss=2.0144662857055664\n",
      "ON EPOCH 90: D_loss=1.0850964784622192, G_loss=1.707322120666504\n",
      "ON EPOCH 91: D_loss=1.0117853879928589, G_loss=1.3518949747085571\n",
      "ON EPOCH 92: D_loss=0.9374451041221619, G_loss=1.372525930404663\n",
      "ON EPOCH 93: D_loss=0.8670040369033813, G_loss=1.5541859865188599\n",
      "ON EPOCH 94: D_loss=0.9899831414222717, G_loss=1.3310694694519043\n",
      "ON EPOCH 95: D_loss=0.8644735813140869, G_loss=1.8134068250656128\n",
      "ON EPOCH 96: D_loss=0.8896570801734924, G_loss=1.244367241859436\n",
      "ON EPOCH 97: D_loss=0.9824420213699341, G_loss=1.5235610008239746\n",
      "ON EPOCH 98: D_loss=1.068702220916748, G_loss=1.3586344718933105\n",
      "ON EPOCH 99: D_loss=0.895492434501648, G_loss=1.470130443572998\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\tsess.run(init)\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\n",
    "\t\tfor i in range(len(train_set) // batch_size):\n",
    "\n",
    "\t\t\t#update discriminator\n",
    "\t\t\tx_ = train_set[i * batch_size:(i + 1) * batch_size]\n",
    "\t\t\ty_ = train_labels[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "\t\t\tbatch_z = np.random.uniform(-1,1,size=(batch_size,100))\n",
    "\n",
    "\t\t\t_, D_loss_curr = sess.run([D_trainer, D_loss] ,feed_dict={real_images:x_, y:y_ ,z:batch_z})\n",
    "            \n",
    "            #update generator\n",
    "\t\t\ty_ = np.random.randint(0, 9, (batch_size, 1))\n",
    "\t\t\ty_ = onehot[y_.astype(np.int32)].squeeze()\n",
    "\t\t\t_, G_loss_curr = sess.run([G_trainer, G_loss] ,feed_dict={z:batch_z, y:y_})\n",
    "\n",
    "\t\tprint(\"ON EPOCH {}: D_loss={}, G_loss={}\".format(epoch,D_loss_curr,G_loss_curr))\n",
    "\n",
    "\t\tsample_z = np.random.uniform(-1,1,size=(1,100))\n",
    "\t\tsample_y = np.random.randint(0, 9, (1, 1))\n",
    "\t\tsample_y = onehot[sample_y.astype(np.int32)].squeeze()\n",
    "\t\tsample_y = sample_y.reshape(1,10)\n",
    "\t\tgen_sample = sess.run(generator(z,y,reuse=True),feed_dict={z:sample_z, y:sample_y})\n",
    "\n",
    "\t\tsamples.append(gen_sample)\t\n",
    "        \n",
    "\tsaver = tf.train.Saver(var_list=g_vars)\n",
    "\tsaver.save(sess, './models/30e_label.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ccd714e5a27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(samples[19].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/30e_label.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver(var_list=g_vars)\n",
    "    saver.restore(sess, './models/30e_label.ckpt')\n",
    "    res_samp = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        gen_z = np.random.uniform(-1,1,size=(1,100))\n",
    "        gen_y = np.array([[8]])\n",
    "        gen_y=onehot[gen_y.astype(np.int32)].squeeze().reshape(1,10)\n",
    "\n",
    "        res_samp.append(sess.run(generator(z, y, reuse=True), feed_dict={z:gen_z, y:gen_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f05e29345c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wD5vCRvDYvytwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05e294c9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(res_samp[6].reshape(28,28), cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
